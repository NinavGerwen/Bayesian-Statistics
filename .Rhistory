b1_t <- rep(NA, 1000)
b2_t <- rep(NA, 1000)
s2_t <- rep(NA, 1000)
## Now, we can start the data simulation through a for loop
for(i in 1:1000) {
## In every loop, we sample one value from all our regression coefficients
b0_t[i] <- sample(LR1.dataframe$b0, 1)
b1_t[i] <- sample(LR1.dataframe$b1, 1)
b2_t[i] <- sample(LR1.dataframe$b2, 1)
s2_t[i] <- sample(LR1.dataframe$vari, 1)
## Then, we create a column of simulated Y values that use the sampled
## regression coefficients through rnorm, where the mean is their
## expected value and the sd is the sampled variance
sim.data[, i] <- rnorm(400, mean = b0_t[i] + b1_t[i]*dat$verbal + b2_t[i]*dat$SES, sd = sqrt(s2_t[i]))
}
## Now, as a discrepancy measure, we calculate the residuals for every
## simulated Y values using their corresponding sampled regression coefficients
residuals_sim <- matrix(data = NA, nrow = 400, ncol = 1000)
for(i in 1:1000) {
residuals_sim[, i] <- sim.data[, i] - b0_t[i] - b1_t[i]*dat$verbal - b2_t[i]*dat$SES
}
## For the observed dataset, we also calculate the residuals a 1000 times
## using the sampled regression coefficients
residuals_obs <- matrix(data = NA, nrow = 400, ncol = 1000)
for(i in 1:1000){
residuals_obs[, i] <- dat$IQ - b0_t[i] - b1_t[i]*dat$verbal - b2_t[i]*dat$SES
}
## ORIGINAL TEST STATISTIC -----------------------------------------------------
## Then, for every column of residuals (simulated and observed), we calculate
## our original test statistic
sim_skewness <- rep(NA, 1000)
for(i in 1:1000) {
sim_skewness[i] <- (mean(residuals_sim[, i]) - median(residuals_sim[, i]))^2
}
obs_skewness <- rep(NA, 1000)
for(i in 1:1000) {
obs_skewness[i] <- (mean(residuals_obs[, i]) - median(residuals_obs[, i]))^2
}
## And we calculate the Posterior Predictive P-value by finding the proportion
## of times that our statistic is larger in the simulated residuals than
## in the observed residuals
ppp_value <- sum(sim_skewness > obs_skewness)/1000
ppp_value
## SKEWNESS STATISTIC ----------------------------------------------------------
library(moments)
obs_skew <- rep(NA, 1000)
sim_skew <- rep(NA, 1000)
## Again, we calculate skewness a thousand times for both the observed
## and simulated residuals
for(i in 1:1000) {
obs_skew[i] <- skewness(residuals_obs[, i])
sim_skew[i] <- skewness(residuals_sim[, i])
}
## And again, we calculate the posterior predictive p-value by finding the
## proportion of times that the skewness for simulated residuals is larger
## than the skewness in the observed residuals
comparison_ppp <- sum(sim_skew > obs_skew)/1000
comparison_ppp
hist(dat$IQ - 12 * dat$verbal - 0.08 * dat$SES)
library(MASS)
## To be able to get the multivariate density, we get
## the means of the posterior distributions regression coefficients
## and the covariance matrix between the two distributions
Means <- c(mean(LR1.dataframe$b1), mean(LR1.dataframe$b2))
Sigma <- cov(LR1.dataframe[2:3])
## Now, we will sample from the posterior and prior distributions
## First set a seed
set.seed(3)
## Then sample from the posterior, using the above specified means and sigma
posterior <- mvrnorm(100000, mu = Means, Sigma = Sigma)
## Calculate the fractional value
b <- 6/400 ## 3 regression coefficients: 3 means, 3 variances --> 6
## Then sample from the prior, using means = 0 and sigma = sigma/b
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/b)
## Finally, we can calculate the Bayes Factor for all our hypotheses
BF.H1 <- (sum(posterior[, 1] > 0 & posterior[, 2] > 0)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] > 0)/100000)
BF.H2 <- (sum(posterior[, 1] > 0 & posterior[, 2] < .1 & posterior[, 2] > -.1)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] < .1 & prior[, 2] > -.1)/100000)
BF.H3 <- (sum(posterior[, 2] > 0 & posterior[, 1] < .1 & posterior[, 1] > -.1)/100000) /
(sum(prior[, 2] > 0 & prior[, 1] < .1 & prior[, 1] > -.1)/100000)
Analysis.3[[2]]
Analysis.3[[3]]
Analysis.3[[4]]
Analysis.3[[5]]
## AUTOCOR PLOTS
autocorrelationplot(V = LR3.dataframe$b0)
autocorrelationplot(V = LR3.dataframe$b1)
autocorrelationplot(V = LR3.dataframe$b2)
autocorrelationplot(V = LR3.dataframe$vari)
## First, we set a seed for reproducibility
set.seed(3)
## Then, we create an empty matrix with equal rows to our original dataset
## and as many columns as we would like datasets
sim.data <- matrix(data = NA, nrow = 400, ncol = 1000)
## Then, we create space for the regression coefficients that we will sample
## so that we can use these to calculate the residuals later
b0_t <- rep(NA, 1000)
b1_t <- rep(NA, 1000)
b2_t <- rep(NA, 1000)
s2_t <- rep(NA, 1000)
## Now, we can start the data simulation through a for loop
for(i in 1:1000) {
## In every loop, we sample one value from all our regression coefficients
b0_t[i] <- sample(LR1.dataframe$b0, 1)
b1_t[i] <- sample(LR1.dataframe$b1, 1)
b2_t[i] <- sample(LR1.dataframe$b2, 1)
s2_t[i] <- sample(LR1.dataframe$vari, 1)
## Then, we create a column of simulated Y values that use the sampled
## regression coefficients through rnorm, where the mean is their
## expected value and the sd is the sampled variance
sim.data[, i] <- rnorm(400, mean = b0_t[i] + b1_t[i]*dat$verbal + b2_t[i]*dat$SES, sd = sqrt(s2_t[i]))
}
## Now, as a discrepancy measure, we calculate the residuals for every
## simulated Y values using their corresponding sampled regression coefficients
residuals_sim <- matrix(data = NA, nrow = 400, ncol = 1000)
for(i in 1:1000) {
residuals_sim[, i] <- sim.data[, i] - b0_t[i] - b1_t[i]*dat$verbal - b2_t[i]*dat$SES
}
## For the observed dataset, we also calculate the residuals a 1000 times
## using the sampled regression coefficients
residuals_obs <- matrix(data = NA, nrow = 400, ncol = 1000)
for(i in 1:1000){
residuals_obs[, i] <- dat$IQ - b0_t[i] - b1_t[i]*dat$verbal - b2_t[i]*dat$SES
}
## ORIGINAL TEST STATISTIC -----------------------------------------------------
## Then, for every column of residuals (simulated and observed), we calculate
## our original test statistic
sim_skewness <- rep(NA, 1000)
for(i in 1:1000) {
sim_skewness[i] <- (mean(residuals_sim[, i]) - median(residuals_sim[, i]))^2
}
obs_skewness <- rep(NA, 1000)
for(i in 1:1000) {
obs_skewness[i] <- (mean(residuals_obs[, i]) - median(residuals_obs[, i]))^2
}
## And we calculate the Posterior Predictive P-value by finding the proportion
## of times that our statistic is larger in the simulated residuals than
## in the observed residuals
ppp_value <- sum(sim_skewness > obs_skewness)/1000
ppp_value
## SKEWNESS STATISTIC ----------------------------------------------------------
library(moments)
obs_skew <- rep(NA, 1000)
sim_skew <- rep(NA, 1000)
## Again, we calculate skewness a thousand times for both the observed
## and simulated residuals
for(i in 1:1000) {
obs_skew[i] <- skewness(residuals_obs[, i])
sim_skew[i] <- skewness(residuals_sim[, i])
}
## And again, we calculate the posterior predictive p-value by finding the
## proportion of times that the skewness for simulated residuals is larger
## than the skewness in the observed residuals
comparison_ppp <- sum(sim_skew > obs_skew)/1000
comparison_ppp
mean(LR1.dataframe$b0)
quantile(LR1.dataframe$b0, probs = c(0.025, 0.975))
mean(LR1.dataframe$b1)
quantile(LR1.dataframe$b1, probs = c(0.025, 0.975))
mean(LR1.dataframe$b2)
quantile(LR1.dataframe$b2, probs = c(0.025, 0.975))
## Visual inspection of the residuals in observed dataset
hist(dat$IQ - 118.3201 - 11.92829 * dat$verbal - 0.003478761 * dat$SES)
mean(dat$IQ - 118.3201 - 11.92829 * dat$verbal - 0.003478761 * dat$SES)
median(dat$IQ - 118.3201 - 11.92829 * dat$verbal - 0.003478761 * dat$SES)
## First, we set a seed for reproducibility
set.seed(3)
## Then, we create an empty matrix with equal rows to our original dataset
## and as many columns as we would like datasets
sim.data <- matrix(data = NA, nrow = 400, ncol = 5000)
## Then, we create space for the regression coefficients that we will sample
## so that we can use these to calculate the residuals later
b0_t <- rep(NA, 5000)
b1_t <- rep(NA, 5000)
b2_t <- rep(NA, 5000)
s2_t <- rep(NA, 5000)
## Now, we can start the data simulation through a for loop
for(i in 1:5000) {
## In every loop, we sample one value from all our regression coefficients
b0_t[i] <- sample(LR1.dataframe$b0, 1)
b1_t[i] <- sample(LR1.dataframe$b1, 1)
b2_t[i] <- sample(LR1.dataframe$b2, 1)
s2_t[i] <- sample(LR1.dataframe$vari, 1)
## Then, we create a column of simulated Y values that use the sampled
## regression coefficients through rnorm, where the mean is their
## expected value and the sd is the sampled variance
sim.data[, i] <- rnorm(400, mean = b0_t[i] + b1_t[i]*dat$verbal + b2_t[i]*dat$SES, sd = sqrt(s2_t[i]))
}
## Now, as a discrepancy measure, we calculate the residuals for every
## simulated Y values using their corresponding sampled regression coefficients
residuals_sim <- matrix(data = NA, nrow = 400, ncol = 5000)
for(i in 1:5000) {
residuals_sim[, i] <- sim.data[, i] - b0_t[i] - b1_t[i]*dat$verbal - b2_t[i]*dat$SES
}
## For the observed dataset, we also calculate the residuals a 1000 times
## using the sampled regression coefficients
residuals_obs <- matrix(data = NA, nrow = 400, ncol = 5000)
for(i in 1:5000){
residuals_obs[, i] <- dat$IQ - b0_t[i] - b1_t[i]*dat$verbal - b2_t[i]*dat$SES
}
## ORIGINAL TEST STATISTIC -----------------------------------------------------
## Then, for every column of residuals (simulated and observed), we calculate
## our original test statistic
sim_skewness <- rep(NA, 5000)
for(i in 1:5000) {
sim_skewness[i] <- (mean(residuals_sim[, i]) - median(residuals_sim[, i]))^2
}
obs_skewness <- rep(NA, 5000)
for(i in 1:5000) {
obs_skewness[i] <- (mean(residuals_obs[, i]) - median(residuals_obs[, i]))^2
}
## And we calculate the Posterior Predictive P-value by finding the proportion
## of times that our statistic is larger in the simulated residuals than
## in the observed residuals
ppp_value <- sum(sim_skewness > obs_skewness)/5000
ppp_value
## SKEWNESS STATISTIC ----------------------------------------------------------
library(moments)
obs_skew <- rep(NA, 5000)
sim_skew <- rep(NA, 5000)
## Again, we calculate skewness a thousand times for both the observed
## and simulated residuals
for(i in 1:5000) {
obs_skew[i] <- skewness(residuals_obs[, i])
sim_skew[i] <- skewness(residuals_sim[, i])
}
## And again, we calculate the posterior predictive p-value by finding the
## proportion of times that the skewness for simulated residuals is larger
## than the skewness in the observed residuals
comparison_ppp <- sum(sim_skew > obs_skew)/5000
comparison_ppp
## Visual inspection of the residuals in observed dataset
hist(dat$IQ - 118.3201 - 11.92829 * dat$verbal - 0.003478761 * dat$SES)
1/5000
BF1_values <- rep(NA, 50)
BF1_values <- rep(NA, 50)
set.seed(3)
posterior <- mvrnorm(100000, mu = Means, Sigma = Sigma)
for(i in 1:50) {
b <- i / 400
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = sigma/b)
BF1_values[i] <- (sum(posterior[, 1] > 0 & posterior[, 2] < .1 & posterior[, 2] > -.1)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] < .1 & prior[, 2] > -.1)/100000)
}
BF1_values <- rep(NA, 50)
set.seed(3)
posterior <- mvrnorm(100000, mu = Means, Sigma = Sigma)
for(i in 1:50) {
b <- as.numeric(i) / 400
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = sigma/b)
BF1_values[i] <- (sum(posterior[, 1] > 0 & posterior[, 2] < .1 & posterior[, 2] > -.1)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] < .1 & prior[, 2] > -.1)/100000)
}
BF1_values <- rep(NA, 50)
set.seed(3)
posterior <- mvrnorm(100000, mu = Means, Sigma = Sigma)
for(i in 1:50) {
b <- as.numeric(i) / 400
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/as.numeric(b))
BF1_values[i] <- (sum(posterior[, 1] > 0 & posterior[, 2] < .1 & posterior[, 2] > -.1)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] < .1 & prior[, 2] > -.1)/100000)
}
BF1_values
plot(x = 1:50, y = BF1_values)
BF1_values <- rep(NA, 100)
set.seed(3)
posterior <- mvrnorm(100000, mu = Means, Sigma = Sigma)
for(i in 1:100) {
b <- as.numeric(i) / 400
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/as.numeric(b))
BF1_values[i] <- (sum(posterior[, 1] > 0 & posterior[, 2] < .1 & posterior[, 2] > -.1)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] < .1 & prior[, 2] > -.1)/100000)
}
plot(x = 1:100, y = BF1_values)
BFH2_values <- rep(NA, 50)
set.seed(3)
posterior <- mvrnorm(100000, mu = Means, Sigma = Sigma)
for(i in 1:50) {
b <- as.numeric(i) / 400
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/as.numeric(b))
BFH2_values[i] <- (sum(posterior[, 1] > 0 & posterior[, 2] < .1 & posterior[, 2] > -.1)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] < .1 & prior[, 2] > -.1)/100000)
}
plot(x = 1:50, y = BFH2_values)
BFH1_values <- rep(NA,50)
for(i in 1:50) {
b <- as.numeric(i) / 400
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/as.numeric(b))
BFH1_values[i] <- (sum(posterior[, 1] > 0 & posterior[, 2] > 0)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] > 0)/100000)
}
plot(x = 1:50, y = BFH1_values)
plot(x = 1:50, y = BFH1_values, ylim = c(0, 5))
plot(x = 1:50, y = BFH2_values)
library(MASS)
## To be able to get the multivariate posterior density, we get
## the means and covariance matrix of the posterior distributions
## from the IV regression coefficients
Means <- c(mean(LR1.dataframe$b1), mean(LR1.dataframe$b2))
Sigma <- cov(LR1.dataframe[2:3])
## Now, we will sample from the posterior and prior distributions
## First set a seed
set.seed(3)
## Then sample from the posterior, using the above specified means and sigma
posterior <- mvrnorm(100000, mu = Means, Sigma = Sigma)
## Calculate the fractional value
b <- 6/400 ## 3 regression coefficients: 3 means, 3 variances --> 6
## Then sample from the prior, using means = 0 and sigma = sigma/b
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/b)
## Finally, we can calculate the Bayes Factor for all our hypotheses
## by stating the correct statements
## For hypothesis 1:
## For both the posterior and prior, we want the proportion of sampled values where both
## regression coefficients are higher than 0 and divide them in the correct way
BF.H1 <- (sum(posterior[, 1] > 0 & posterior[, 2] > 0)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] > 0)/100000)
## For hypothesis 2:
## For both posterior and prior, the first regression coefficient should be higher
## than 0 and the second one should be close to zero (i.e., -.1 < x < .1)
BF.H2 <- (sum(posterior[, 1] > 0 & posterior[, 2] < .1 & posterior[, 2] > -.1)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] < .1 & prior[, 2] > -.1)/100000)
## For hypothesis 3:
## Exactly the other way around from hypothesis 2
BF.H3 <- (sum(posterior[, 2] > 0 & posterior[, 1] < .1 & posterior[, 1] > -.1)/100000) /
(sum(prior[, 2] > 0 & prior[, 1] < .1 & prior[, 1] > -.1)/100000)
for(i in 1:50) {
b <- as.numeric(i) / 400
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/as.numeric(b))
BFH1_values[i] <- (sum(posterior[, 1] > 0 & posterior[, 2] > 0)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] > 0)/100000)
}
plot(x = 1:50, y = BFH1_values, ylim = c(0, 5))
for(i in 1:50) {
b <- as.numeric(i) / 400
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/as.numeric(b))
BFH2_values[i] <- (sum(posterior[, 1] > 0 & posterior[, 2] < .1 & posterior[, 2] > -.1)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] < .1 & prior[, 2] > -.1)/100000)
}
plot(x = 1:50, y = BFH2_values)
BFH1_values <- rep(NA,50)
plot(x = 1:50, y = BFH1_values, ylim = c(0, 5))
plot(x = 1:50, y = BFH2_values)
plot(x = 1:50, y = BFH1_values, ylim = c(0, 5))
library(MASS)
## To be able to get the multivariate posterior density, we get
## the means and covariance matrix of the posterior distributions
## from the IV regression coefficients
Means <- c(mean(LR1.dataframe$b1), mean(LR1.dataframe$b2))
Sigma <- cov(LR1.dataframe[2:3])
## Now, we will sample from the posterior and prior distributions
## First set a seed
set.seed(3)
## Then sample from the posterior, using the above specified means and sigma
posterior <- mvrnorm(100000, mu = Means, Sigma = Sigma)
## Calculate the fractional value
b <- 6/400 ## 3 regression coefficients: 3 means, 3 variances --> 6
## Then sample from the prior, using means = 0 and sigma = sigma/b
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/b)
## Finally, we can calculate the Bayes Factor for all our hypotheses
## by stating the correct statements
## For hypothesis 1:
## For both the posterior and prior, we want the proportion of sampled values where both
## regression coefficients are higher than 0 and divide them in the correct way
BF.H1 <- (sum(posterior[, 1] > 0 & posterior[, 2] > 0)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] > 0)/100000)
## For hypothesis 2:
## For both posterior and prior, the first regression coefficient should be higher
## than 0 and the second one should be close to zero (i.e., -.1 < x < .1)
BF.H2 <- (sum(posterior[, 1] > 0 & posterior[, 2] < .1 & posterior[, 2] > -.1)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] < .1 & prior[, 2] > -.1)/100000)
## For hypothesis 3:
## Exactly the other way around from hypothesis 2
BF.H3 <- (sum(posterior[, 2] > 0 & posterior[, 1] < .1 & posterior[, 1] > -.1)/100000) /
(sum(prior[, 2] > 0 & prior[, 1] < .1 & prior[, 1] > -.1)/100000)
BFH1_values <- rep(NA,50)
for(i in 1:50) {
b <- as.numeric(i) / 400
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/as.numeric(b))
BFH1_values[i] <- (sum(posterior[, 1] > 0 & posterior[, 2] > 0)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] > 0)/100000)
}
plot(x = 1:50, y = BFH1_values, ylim = c(0, 5))
BFH2_values <- rep(NA, 50)
for(i in 1:50) {
b <- as.numeric(i) / 400
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/as.numeric(b))
BFH2_values[i] <- (sum(posterior[, 1] > 0 & posterior[, 2] < .1 & posterior[, 2] > -.1)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] < .1 & prior[, 2] > -.1)/100000)
}
plot(x = 1:50, y = BFH2_values)
BFH1_values <- rep(NA,50)
plot(x = 1:50, y = BFH2_values)
plot(x = 1:50, y = BFH1_values, ylim = c(0, 5))
plot(x = 1:50, y = BFH1_values)
plot(x = 1:50, y = BFH1_values)
BFH1_values
BFH1_values <- rep(NA,50)
for(i in 1:50) {
b <- as.numeric(i) / 400
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/as.numeric(b))
BFH1_values[i] <- (sum(posterior[, 1] > 0 & posterior[, 2] > 0)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] > 0)/100000)
}
plot(x = 1:50, y = BFH1_values)
plot(x = 1:50, y = BFH1_values, ylim = c(0, 5))
library(MASS)
## To be able to get the multivariate posterior density, we get
## the means and covariance matrix of the posterior distributions
## from the IV regression coefficients
Means <- c(mean(LR1.dataframe$b1), mean(LR1.dataframe$b2))
Sigma <- cov(LR1.dataframe[2:3])
## Now, we will sample from the posterior and prior distributions
## First set a seed
set.seed(3)
## Then sample from the posterior, using the above specified means and sigma
posterior <- mvrnorm(100000, mu = Means, Sigma = Sigma)
## Calculate the fractional value
b <- 6/400 ## 3 regression coefficients: 3 means, 3 variances --> 6
## Then sample from the prior, using means = 0 and sigma = sigma/b
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/b)
## Finally, we can calculate the Bayes Factor for all our hypotheses
## by stating the correct statements
## For hypothesis 1:
## For both the posterior and prior, we want the proportion of sampled values where both
## regression coefficients are higher than 0 and divide them in the correct way
BF.H1 <- (sum(posterior[, 1] > 0 & posterior[, 2] > 0)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] > 0)/100000)
## For hypothesis 2:
## For both posterior and prior, the first regression coefficient should be higher
## than 0 and the second one should be close to zero (i.e., -.1 < x < .1)
BF.H2 <- (sum(posterior[, 1] > 0 & posterior[, 2] < .1 & posterior[, 2] > -.1)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] < .1 & prior[, 2] > -.1)/100000)
## For hypothesis 3:
## Exactly the other way around from hypothesis 2
BF.H3 <- (sum(posterior[, 2] > 0 & posterior[, 1] < .1 & posterior[, 1] > -.1)/100000) /
(sum(prior[, 2] > 0 & prior[, 1] < .1 & prior[, 1] > -.1)/100000)
BFH1_values <- rep(NA,50)
for(i in 1:50) {
b <- as.numeric(i) / 400
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/as.numeric(b))
BFH1_values[i] <- (sum(posterior[, 1] > 0 & posterior[, 2] > 0)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] > 0)/100000)
}
plot(x = 1:50, y = BFH1_values, ylim = c(0, 5))
BFH2_values <- rep(NA, 50)
for(i in 1:50) {
b <- as.numeric(i) / 400
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/as.numeric(b))
BFH2_values[i] <- (sum(posterior[, 1] > 0 & posterior[, 2] < .1 & posterior[, 2] > -.1)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] < .1 & prior[, 2] > -.1)/100000)
}
plot(x = 1:50, y = BFH2_values)
BFH1_values <- rep(NA,50)
plot(x = 1:50, y = BFH1_values, ylim = c(0, 5))
BFH1_values <- rep(NA, 50)
for(i in 1:50) {
b <- as.numeric(i) / 400
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/as.numeric(b))
BFH1_values[i] <- (sum(posterior[, 1] > 0 & posterior[, 2] > 0)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] > 0)/100000)
}
library(MASS)
## To be able to get the multivariate posterior density, we get
## the means and covariance matrix of the posterior distributions
## from the IV regression coefficients
Means <- c(mean(LR1.dataframe$b1), mean(LR1.dataframe$b2))
Sigma <- cov(LR1.dataframe[2:3])
## Now, we will sample from the posterior and prior distributions
## First set a seed
set.seed(3)
## Then sample from the posterior, using the above specified means and sigma
posterior <- mvrnorm(100000, mu = Means, Sigma = Sigma)
## Calculate the fractional value
b <- 6/400 ## 3 regression coefficients: 3 means, 3 variances --> 6
## Then sample from the prior, using means = 0 and sigma = sigma/b
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/b)
## Finally, we can calculate the Bayes Factor for all our hypotheses
## by stating the correct statements
## For hypothesis 1:
## For both the posterior and prior, we want the proportion of sampled values where both
## regression coefficients are higher than 0 and divide them in the correct way
BF.H1 <- (sum(posterior[, 1] > 0 & posterior[, 2] > 0)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] > 0)/100000)
## For hypothesis 2:
## For both posterior and prior, the first regression coefficient should be higher
## than 0 and the second one should be close to zero (i.e., -.1 < x < .1)
BF.H2 <- (sum(posterior[, 1] > 0 & posterior[, 2] < .1 & posterior[, 2] > -.1)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] < .1 & prior[, 2] > -.1)/100000)
## For hypothesis 3:
## Exactly the other way around from hypothesis 2
BF.H3 <- (sum(posterior[, 2] > 0 & posterior[, 1] < .1 & posterior[, 1] > -.1)/100000) /
(sum(prior[, 2] > 0 & prior[, 1] < .1 & prior[, 1] > -.1)/100000)
## Sensitivity analysis for H1 and H2
BFH1_values <- rep(NA, 50)
for(i in 1:50) {
b <- as.numeric(i) / 400
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/as.numeric(b))
BFH1_values[i] <- (sum(posterior[, 1] > 0 & posterior[, 2] > 0)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] > 0)/100000)
}
plot(x = 1:50, y = BFH1_values, ylim = c(0, 5))
BFH2_values <- rep(NA, 50)
for(i in 1:50) {
b <- as.numeric(i) / 400
prior <- mvrnorm(100000, mu = c(0, 0), Sigma = Sigma/as.numeric(b))
BFH2_values[i] <- (sum(posterior[, 1] > 0 & posterior[, 2] < .1 & posterior[, 2] > -.1)/100000) /
(sum(prior[, 1] > 0 & prior[, 2] < .1 & prior[, 2] > -.1)/100000)
}
plot(x = 1:50, y = BFH2_values)
plot(x = 1:50, y = BFH1_values, ylim = c(0, 5))
plot(x = 1:50, y = BFH2_values)
