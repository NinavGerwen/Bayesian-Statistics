MyPermutationTest <- function(x, y) {
## initial t-value
initial_t <- t.test(x, y)$statistic
t_values <- rep(0, 250)
## creating 250 permutation samples and calculating t-statistic for each sample
for(i in 1:250) {
temp_sample <- sample(x = c(x, y), replace = FALSE)
## First XX number of elements go to the first group...
S1 <- temp_sample[1:length(x)]
## Then the rest goes to the second group
S2 <- temp_sample[(length(x) + 1):(length(x)+length(y))]
t_values[i] <- t.test(S1, S2)$statistic
}
## histogram of the t-statistic distribution with a vertical line at the initial t-value
hist(t_values, breaks = 50)
abline(v = initial_t, col = "red")
## proportion of times the t-statistic is larger than the t-statistic value in the original sample
empirical_p_value <- sum(initial_t > t_values)/250
return(empirical_p_value)
}
MyBootstrapTest <- function(x, y) {
## initial t-value
initial_t <- t.test(x, y)$statistic
t_values <- rep(0, 250)
## The bootstrapping
for(i in 1:250) {
temp_sample <- sample(x = c(x, y), replace = TRUE)
## First XX number of elements go to the first group...
S1 <- temp_sample[1:length(x)]
## Then the rest goes to the second group
S2 <- temp_sample[(length(x) + 1):(length(x)+length(y))]
t_values[i] <- t.test(S1, S2)$statistic
}
## histogram of the t-statistic distribution with a vertical line at the initial t-value
hist(t_values, breaks = 50)
abline(v = initial_t, col = "red")
## proportion of times the t-statistic is larger than th et-statistic value in the original sample
empirical_p_value <- sum(initial_t > t_values)/250
return(empirical_p_value)
}
MyPermutationTest(V1, V2)
MyBootstrapTest(V1, V2)
MyPermutationTest <- function(x, y) {
## initial t-value
initial_t <- t.test(x, y)$statistic
t_values <- rep(0, 250)
## creating 250 permutation samples and calculating t-statistic for each sample
for(i in 1:250) {
temp_sample <- sample(x = c(x, y), replace = FALSE)
## First XX number of elements go to the first group...
S1 <- temp_sample[1:length(x)]
## Then the rest goes to the second group
S2 <- temp_sample[(length(x) + 1):(length(x)+length(y))]
t_values[i] <- t.test(S1, S2)$statistic
}
## histogram of the t-statistic distribution with a vertical line at the initial t-value
hist(t_values, breaks = 25)
abline(v = initial_t, col = "red")
## proportion of times the t-statistic is larger than the t-statistic value in the original sample
empirical_p_value <- sum(initial_t > t_values)/250
return(empirical_p_value)
}
MyBootstrapTest <- function(x, y) {
## initial t-value
initial_t <- t.test(x, y)$statistic
t_values <- rep(0, 250)
## The bootstrapping
for(i in 1:250) {
temp_sample <- sample(x = c(x, y), replace = TRUE)
## First XX number of elements go to the first group...
S1 <- temp_sample[1:length(x)]
## Then the rest goes to the second group
S2 <- temp_sample[(length(x) + 1):(length(x)+length(y))]
t_values[i] <- t.test(S1, S2)$statistic
}
## histogram of the t-statistic distribution with a vertical line at the initial t-value
hist(t_values, breaks = 25)
abline(v = initial_t, col = "red")
## proportion of times the t-statistic is larger than th et-statistic value in the original sample
empirical_p_value <- sum(initial_t > t_values)/250
return(empirical_p_value)
}
MyPermutationTest(V1, V2)
MyBootstrapTest(V1, V2)
MyBootstrapTest <- function(x, y) {
## initial t-value
initial_t <- t.test(x, y)$statistic
t_values <- rep(0, 250)
## The bootstrapping
for(i in 1:250) {
temp_sample <- sample(x = c(x, y), replace = TRUE)
## First XX number of elements go to the first group...
S1 <- temp_sample[1:length(x)]
## Then the rest goes to the second group
S2 <- temp_sample[(length(x) + 1):(length(x)+length(y))]
t_values[i] <- t.test(S1, S2)$statistic
}
## histogram of the t-statistic distribution with a vertical line at the initial t-value
hist(t_values, breaks = 25, col = "blue")
abline(v = initial_t, col = "red")
## proportion of times the t-statistic is larger than th et-statistic value in the original sample
empirical_p_value <- sum(initial_t > t_values)/250
return(empirical_p_value)
}
MyBootstrapTest(V1, V2)
MyBootstrapTest <- function(x, y) {
## initial t-value
initial_t <- t.test(x, y)$statistic
t_values <- rep(0, 250)
## The bootstrapping
for(i in 1:250) {
temp_sample <- sample(x = c(x, y), replace = TRUE)
## First XX number of elements go to the first group...
S1 <- temp_sample[1:length(x)]
## Then the rest goes to the second group
S2 <- temp_sample[(length(x) + 1):(length(x)+length(y))]
t_values[i] <- t.test(S1, S2)$statistic
}
## histogram of the t-statistic distribution with a vertical line at the initial t-value
hist(t_values, breaks = 25, col = "teal")
abline(v = initial_t, col = "red")
## proportion of times the t-statistic is larger than th et-statistic value in the original sample
empirical_p_value <- sum(initial_t > t_values)/250
return(empirical_p_value)
}
MyPermutationTest(V1, V2)
MyBootstrapTest(V1, V2)
MyBootstrapTest <- function(x, y) {
## initial t-value
initial_t <- t.test(x, y)$statistic
t_values <- rep(0, 250)
## The bootstrapping
for(i in 1:250) {
temp_sample <- sample(x = c(x, y), replace = TRUE)
## First XX number of elements go to the first group...
S1 <- temp_sample[1:length(x)]
## Then the rest goes to the second group
S2 <- temp_sample[(length(x) + 1):(length(x)+length(y))]
t_values[i] <- t.test(S1, S2)$statistic
}
## histogram of the t-statistic distribution with a vertical line at the initial t-value
hist(t_values, breaks = 25)
abline(v = initial_t, col = "red")
## proportion of times the t-statistic is larger than th et-statistic value in the original sample
empirical_p_value <- sum(initial_t > t_values)/250
return(empirical_p_value)
}
MyPermutationTest(V1, V2)
MyBootstrapTest(V1, V2)
MyPermutationTest <- function(x, y) {
## initial t-value
initial_t <- t.test(x, y)$statistic
t_values <- rep(0, 250)
## creating 250 permutation samples and calculating t-statistic for each sample
for(i in 1:250) {
temp_sample <- sample(x = c(x, y), replace = FALSE)
## First XX number of elements go to the first group...
S1 <- temp_sample[1:length(x)]
## Then the rest goes to the second group
S2 <- temp_sample[(length(x) + 1):(length(x)+length(y))]
t_values[i] <- t.test(S1, S2)$statistic
}
## histogram of the t-statistic distribution with a vertical line at the initial t-value
hist(t_values, breaks = 25)
abline(v = initial_t, col = "red")
## proportion of times the t-statistic is larger than the t-statistic value in the original sample
empirical_p_value <- sum(initial_t > t_values)/250
return(empirical_p_value)
}
MyPermutationTest(V1, V2)
MyBootstrapTest(V1, V2)
?cumsum
A <- matrix(nrow = 20, ncol = 60)
View(A)
for(i in 1:20) {
simulate <- rnorm(60, 0.0, 0.13)
test <- cumsum(simulate)
}
for(i in 1:20) {
simulate <- rnorm(60, 0.0, 0.13)
test <- cumsum(simulate)
A[, i] <- test
}
View(A)
for(i in 1:20) {
simulate <- rnorm(60, 0.0, 0.13)
test <- cumsum(simulate)
A[, i] <- c(test)
}
A <- matrix(nrow = 20, ncol = 60)
for(i in 1:20) {
simulate <- rnorm(60, 0.0, 0.13)
test <- cumsum(simulate)
A[i, ] <- c(test)
}
View(A)
A
A <- matrix(nrow = 20, ncol = 60)
for(i in 1:20) {
simulate <- rnorm(60, 0.0, 0.13)
test <- cumsum(simulate)
A[i, ] <- test
}
View(A)
A <- matrix(nrow = 20, ncol = 60)
for(i in 1:20) {
simulate <- rnorm(60, 0.0, 0.13)
simulate <- cumsum(simulate)
A[i,  ] <- simulate
}
View(A)
A <- data.frame(nrow = 20, ncol = 60)
for(i in 1:20) {
simulate <- rnorm(60, 0.0, 0.13)
simulate <- cumsum(simulate)
A[i,  ] <- simulate
}
View(A)
A <- data.frame(nrow = 20, ncol = 60)
A <- as.data.frame(matrix(nrow = 20, ncol = 60))
View(A)
for(i in 1:20) {
simulate <- rnorm(60, 0.0, 0.13)
simulate <- cumsum(simulate)
A[i,  ] <- simulate
}
View(A)
plot(A[1])
plot(A)
A$ID <- 1:20
View(A)
plot(A$ID, A[1:20, ])
plot(x = 1:20, A)
plot(x = 1:20)
plot(1:60)
plot(1:60, y = A)
library(ggplot)
library(ggplot2)
ggplot(data = A, aes(x = colnames(A), y = A[1:60]))
ggplot(data = A, aes(x = colnames(A), y = A[, 1:60]))
ggplot(data = A, aes(x = 1:60))
ggplot(data = A, aes(x = 1:60, y = 10))
ggplot(data = A, aes(x = 60, y = 10))
ggplot(data = A, aes(x = 1:60, y = 10))
ggplot(data = A, aes(x = , y = 10, colour = ID)) + geom_line()
ggplot(data = A, aes(x = 10, y = 10, colour = ID)) + geom_line()
A$ID <- as.factor(1:20)
library(ggplot2)
ggplot(data = A, aes(x = 10, y = 10, colour = ID)) + geom_line()
?melt
??melt
rownames(A)
t(A)
transA <- t(A)
transA <- data.frame(t(A))
rownames(transA)
rownames(transA) <- 1:60
rownames(transA) <- 1:61
transA$car <- rownames(transA) <- 1:61
View(transA)
ggplot(data = A, aes(x = as.numeric(car), y = value, colour = ID)) + geom_line()
transA <- data.frame(t(A))
transA$car <- rownames(transA) <- 1:61
library(ggplot2)
ggplot(data = A, aes(x = as.numeric(car), y = , colour = ID)) + geom_line()
ggplot(data = transA, aes(x = as.numeric(car), y = , colour = ID)) + geom_line()
View(transA)
ggplot(data = transA, aes(x = as.numeric(car), y = 1:20, colour = ID)) + geom_line()
View(A)
library(reshape2)
transA <- melt(transA, id.vars = "ID")
A <- as.data.frame(matrix(nrow = 20, ncol = 60))
for(i in 1:20) {
simulate <- rnorm(60, 0.0, 0.13)
simulate <- cumsum(simulate)
A[i,  ] <- simulate
}
A$ID <- as.factor(1:20)
transA <- data.frame(t(A))
View(transA)
A <- as.data.frame(matrix(nrow = 20, ncol = 60))
for(i in 1:20) {
simulate <- rnorm(60, 0.0, 0.13)
simulate <- cumsum(simulate)
A[i,  ] <- simulate
}
transA <- data.frame(t(A))
A$ID <- as.factor(1:20)
View(A)
transA$ID <- as.factor(1:60)
transA <- melt(transA, id.vars = "ID")
View(transA)
ggplot(data = transA, aes(x = as.numeric(car), y = value, colour = ID)) + geom_line()
ggplot(data = transA, aes(x = as.numeric(ID), y = value, colour = ID)) + geom_line()
ggplot(data = transA, aes(x = as.numeric(ID), y = value, colour = variable)) + geom_line()
View(transA)
X <- c(1:20)
Y <- runif(1, 0, 20)
x[Y]
x[Y]
x[Y]
X[Y]
Y <- runif(1, 0, 20)
X[Y]
Y <- runif(1, 0, 20)
X[Y]
round(Y)
Y <- round(runif(1, 0, 20))
X[Y]
Y <- round(runif(1, 0, 20))
X[Y]
temp_sample <- rep(0, 20)
X <- c(1:20)
temp_sample <- rep(0, 20)
for(i in length(X)) {
Y <- round(runif(1, 0, 20))
temp_sample[i] <- X[Y]
}
for(i in 1:length(X)) {
Y <- round(runif(1, 0, 20))
temp_sample[i] <- X[Y]
}
runif(1, 0, 1)
round(runif(1,0,1))
round(runif(1,0,1))
round(runif(1,0,1))
t_values[i] <- t.test(S1, S2)$statistic
round(runif(1,0,1))
round(runif(1,0,1))
round(runif(1,0,1))
round(runif(1,0,1))
round(runif(1,0,1))
round(runif(1,0,1))
round(runif(1,0,1))
round(runif(1,0,1))
V1[0]
V1[1]
install.packages(rjags)
install.packages("rjags")
library("rjags")
version
library("rjags")
?rjags
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
library(haven)
setwd("~/GitHub/Bayesian-Statistics")
ex2 <- read_sav("Exercise 2 - Data.sav")
View(ex2)
?dnorm
?inprod
?jags.model
library(rjags)
library(haven)
library(rjags)
ex2 <- read_sav("Exercise 2 - Data.sav")
?jags.model
source('Exercise 1 - Data.txt')
View(dat)
list(2)
list(c(1:5))
lists(c(1:5), c(1:10))
list(1)
View(dat)
list(list(1), list(-1))
model.def <- jags.model(file = "Exercise 2 - Model.txt", data = ex2, n.chains = 2, inits = list(list(1), list(-1)))
N = 172
model.def <- jags.model(file = "Exercise 2 - Model.txt", data = ex2, n.chains = 2, inits = list(list(1), list(-1)))
model.def <- jags.model(file = "Exercise 2 - Model.txt", data = ex2, n.chains = 2, inits = list(list(1), list(-1)))
model.def <- jags.model(file = "Exercise 2 - Model.txt", data = ex2, n.chains = 2, inits = list(list(1), list(-1)))
model.def <- jags.model(file = "Exercise 2 - Model.txt", data = ex2, n.chains = 2, inits = list(list(1), list(-1)))
model.def <- jags.model(file = "Exercise 2 - Model.txt", data = ex2, n.chains = 2, inits = list(list(1), list(-1)))
model.def <- jags.model(file = "Exercise 2 - Model.txt", data = ex2, n.chains = 2, inits = list(list(1), list(-1)))
model.def <- jags.model(file = "Exercise 2 - Model.txt", data = ex2, n.chains = 2, inits = list(list(1), list(-1)))
model.def <- jags.model(file = "Exercise 2 - Model.txt", data = ex2, n.chains = 2, inits = list(list(1), list(-1)))
library(haven)
library(rjags)
ex2 <- read_sav("Exercise 2 - Data.sav")
model.def <- jags.model(file = "Exercise 2 - Model.txt", data = ex2, n.chains = 2, inits = list(list(1), list(-1)))
model.def <- jags.model(file = "Exercise 2 - Model.txt", data = ex2, n.chains = 2, inits = list(list(1), list(-1)))
model.def <- jags.model(file = "Exercise 2 - Model.txt", data = ex2, n.chains = 2, inits = list(beta0 = 0, beta1 = c(-1, 1), beta2 = c(1.03, 2.03)))
list(beta0 = 0, beta1 = c(-1, 1), beta2 = c(1.03, 2.03))
model.def <- jags.model(file = "Exercise 2 - Model.txt", data = ex2, n.chains = 2, inits = list(beta0 = 0, beta1 = c(3, 1), beta2 = c(1.03, 2.03)))
model.def <- jags.model(file = "Exercise 2 - Model.txt", data = ex2, n.chains = 2, inits = list(beta0 = 0, beta1 = 3, beta2 = 2.03))
update(model.def, n.iter = 1500)
parameters <- c("beta0", "beta1", "beta2", "sigma")
results <- coda.samples(model = model.def, variable.names = parameters, n.iter = 10000)
summary(results)
parameters <- c("beta0", "beta1", "beta2", "sigma")
set.seed(3)
results <- coda.samples(model = model.def, variable.names = parameters, n.iter = 10000)
summary(results)
plot(results)
## Autocorrelation plots
autocorr.plot(results)
## Gelman-Rubin diagnostic plot
gelman.plot(results)
## History plot per parameter
plot(results)
## History plot per parameter
plot(results)
## Autocorrelation plots
autocorr.plot(results)
## Gelman-Rubin diagnostic plot
gelman.plot(results)
int.model.def <- jags.model(file = "Exercise 2 - Model.txt", data = ex2, n.chains = 2, inits = list(beta0 = 0, beta1 = 3, beta2 = 2.03, beta3 = 1.09))
update(int.model.def, n.iter = 1500)
parameters <- c("beta0", "beta1", "beta2", "beta3", "sigma")
set.seed(3)
int.results <- coda.samples(model = int.model.def, variable.names = parameters, n.iter = 10000)
summary(int.results)
plot(results)
int.model.def <- jags.model(file = "Exercise 2 - Model.txt", data = ex2, n.chains = 2, inits = list(beta0 = 0, beta1 = 3, beta2 = 2.03, beta3 = 1.09))
update(int.model.def, n.iter = 1500)
int.parameters <- c("beta0", "beta1", "beta2", "beta3", "sigma")
set.seed(3)
int.results <- coda.samples(model = int.model.def, variable.names = int.parameters, n.iter = 10000)
summary(int.results)
plot(int.results)
autocorr.plot(int.results)
gelman.plot(int.results)
## First, all priors have to be set
a.prior <- 0.001
b.prior <- 0.001
mu0 <- 1
sigma0 <- 10000
mu1 <- 1
sigma1 <- 10000
mu2 <- 1
sigma2 <- 10000
GibbsSampler <- function(Y, X1, X2, burn.in = 1000, iterations = 10000, initial.values = c(1.5, 2, 0.5)) {
## First create space
b0 <- rep(0, iterations)
b1 <- rep(0, iterations)
b2 <- rep(0, iterations)
vari <- rep(0, iterations)
## Then assume the specified initial values
b0[1] <- initial.values[1]
b1[1] <- initial.values[2]
b2[1] <- initial.values[3]
vari[1] <- 1
N <- length(Y)
## In every iteration, the values of the parameters of the conditional
## posteriors should be calculated as functions of the prior parameters,
## the data and the current values of the other model parameters
for(i in 2:iterations) {
## First, we should update the parameters of the intercept (mean and standard deviation) with the following formula:
## 10000 because informative prior?
mean.0.post <- (sum(Y - b1[i - 1]*X1 - b2[i - 1]*X2, na.rm = TRUE)/vari[i - 1] + (mu0 / sigma0)) / ((N / vari[i - 1]) + (mu0 / sigma0))
sd.0.post <- 1 / ((N / vari[i - 1]) + (mu0 / sigma0))
## Then through rnorm we randomly sample from a normal distribution the next value for b0 with the
## above calculated mean and standard deviation
b0[i] <- rnorm(n = 1, mean = mean.0.post, sd = sd.0.post)
## Now, we can update the mean and standard deviation of the regression coefficient for the first variable
## using the updated value of the intercept
mean.1.post <- (sum(X1*(Y - b0[i] - b2[i - 1]*X2), na.rm = TRUE)/vari[i - 1] + (mu1 / sigma1)) / sum(X1^2, na.rm = TRUE)/vari[i - 1] + (mu1 / sigma1)
sd.1.post <- 1/((sum(X1^2, na.rm = TRUE) / vari[i - 1]) + (mu1 / sigma1))
## Then again we randomly sample a new b1
b1[i] <- rnorm(n = 1, mean = mean.1.post, sd = sd.1.post)
## Afterwards, we update the mean and standard deviation of the regression coefficient for the second variable
## using the updated value of both the intercept and b1
mean.2.post <- (sum(X2*(Y - b0[i] - b1[i]*X1), na.rm = TRUE)/vari[i - 1] + (mu2 / sigma2)) / sum(X2^2, na.rm = TRUE)/vari[i - 1] + (mu2 / sigma2)
sd.2.post <- 1/((sum(X2^2, na.rm = TRUE) / vari[i - 1]) + (mu2 / sigma2))
## Then, we randomly sample a new b2
b2[i] <- rnorm(n = 1, mean = mean.2.post, sd = sd.2.post)
## Finally, we update the parameters for the distribution of our standard deviation using all above updated values
a.post <- N / 2 + a.prior
b.post <- sum((Y - (b0[i] + b1[i]*X1 + b2[i]*X2))^2, na.rm = TRUE) / 2 + b.prior
## And randomly sample a new variance again for
vari[i] <- 1/rgamma(n = 1, shape = a.post, rate = b.post)
}
b0 <- b0[-c(1:burn.in)]
b1 <- b1[-c(1:burn.in)]
b2 <- b2[-c(1:burn.in)]
vari <- vari[-c(1:burn.in)]
## Now, we also want the posterior distributions (histograms) of all parameters
par(mfrow = c(2,2))
hist(b0)
abline(v = mean(b0), col = "blue")
hist(b1)
abline(v = mean(b1), col = "blue")
hist(b2)
abline(v = mean(b2), col = "blue")
hist(vari)
data_frame <- as.data.frame(cbind(b0, b1, b2, vari, iter = 1:length(b0)))
traceplot1 <- ggplot(data_frame, aes(x=iter, y=b0)) +
geom_line() +
labs(title="b0 trace")
traceplot1
traceplot2 <- ggplot(data_frame, aes(x=iter, y=b1)) +
geom_line() +
labs(title="b1 trace")
traceplot2
traceplot3 <- ggplot(data_frame, aes(x=iter, y=b2)) +
geom_line() +
labs(title="b2 trace")
traceplot3
traceplot4 <- ggplot(data_frame, aes(x=iter, y=vari)) +
geom_line() +
labs(title="var trace")
traceplot4
list_of_output <- list(data_frame, traceplot1, traceplot2, traceplot3, traceplot4)
return(list_of_output)
}
## test the sampler
library(haven)
data <- read_sav("Exercise 2 - Data.sav")
str(data)
summary(lm(attitude ~ extraversion + agreeableness, data = data))
GibbsSampler(data$attitude, data$extraversion, data$agreeableness, burn.in = 1000, iterations = 10000)
library(ggplot2)
GibbsSampler(data$attitude, data$extraversion, data$agreeableness, burn.in = 1000, iterations = 10000)
